{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: \n",
    "\n",
    "<div class=\"line-block\"><code>1   It does not print the fruit at the correct index, why is the returned result wrong?</code><br />\n",
    "<code>2   How could this be fixed?</code></div>\n",
    "\n",
    "### Solution: \n",
    " The issue with the code is that all the fruits all in a set and the problem with a set is that it is not in an order. So, for returning the correct fruit name for each fruit id, we should use a List instead of a Set. (As shown below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_fruit(fruit_id: int, fruits: list) -> str:\n",
    "    \n",
    "    if fruit_id < 0 or fruit_id >= len(fruits):\n",
    "        raise ValueError(f\"Fruit with id {fruit_id} does not exist\")\n",
    "    return fruits[fruit_id]\n",
    "\n",
    "fruits = [\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"]\n",
    "name1 = id_to_fruit(1, fruits)\n",
    "name3 = id_to_fruit(3, fruits)\n",
    "name4 = id_to_fruit(4, fruits)\n",
    "print(name1,name3,name4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "\n",
    "<div class=\"line-block\"><code>1   Can you spot the obvious error?</code><br />\n",
    "<code>2   After fixing the obvious error it is still wrong, how can this be fixed?</code></div>\n",
    "\n",
    "### Solution: \n",
    "The obvious error is:\n",
    "\n",
    " ```coords[:, 0], coords[:, 1], ... = coords[:, 1], coords[:, 1], ... ```\n",
    "\n",
    "it should be:\n",
    "\n",
    " ```coords[:, 0], coords[:, 1], ... = coords[:, 1], coords[:, 0], ....```\n",
    "\n",
    "Also, by printing out the \"swapped_croods\", we would get all the Y coordinates as all the X coordinates, which is wrong. (regarding that we only needed them to be flipped.)\n",
    "And as a solution, we can copy each coords on the other side, so that we wouldn't have the same columns of Y(s) where the X column sits. (as shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def swap(coords: np.ndarray):\n",
    "    coords[:, 0], coords[:, 1], coords[:, 2], coords[:, 3] = coords[:, 1].copy(), coords[:, 0].copy(), coords[:, 3].copy(), coords[:, 2].copy()\n",
    "    return coords\n",
    "\n",
    "coords = np.array([[10, 5, 15, 6, 0],\n",
    "                   [11, 3, 13, 6, 0],\n",
    "                   [5, 3, 13, 6, 1],\n",
    "                   [4, 4, 13, 6, 1],\n",
    "                   [6, 5, 13, 16, 1]])\n",
    "swapped_coords = swap(coords)\n",
    "\n",
    "print(swapped_coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercies 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. For some reason the plot is not showing correctly, can you find out what is going wrong?`\n",
    "\n",
    "`2. How could this be fixed?`\n",
    "\n",
    "### Solution: \n",
    "\n",
    "The x and y values are being interchanged in the plot. The CSV file lists precision in the first column and recall in the second column. However, the plot function is erroneously plotting recall on the x-axis and precision on the y-axis.\n",
    "\n",
    "To rectify this, we should interchange the columns when plotting. we can use the `pandas` library to streamline CSV file reading for improved efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def plot_data(csv_file_path: str):\n",
    "    # load data\n",
    "    results = []\n",
    "    with open(csv_file_path) as result_csv:\n",
    "        csv_reader = csv.reader(result_csv, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        results = np.stack(results)\n",
    "    plt.plot(results[:, 0], results[:, 1])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exerecise 4: \n",
    "\n",
    "`1   Changing the batch_size from 32 to 64 triggers the structural bug.`\n",
    "\n",
    "`2. Can you also spot the cosmetic bug?`\n",
    "\n",
    "\n",
    "### Solution:\n",
    "\n",
    "The bug trigged by changing the batch size to 64 is caused by a mismatch between the size of the discriminator output and the label sizes. The discriminator output size is based on the batch size, but the label sizes are hardcoded to 32. to fix this change these two lines: \n",
    "\n",
    " ``` real_samples_labels = torch.ones((batch_size, 1)).to(device=device) ```\n",
    " ``` generated_samples_labels = torch.zeros((batch_size, 1)).to(device=device)``` \n",
    "\n",
    "into these:\n",
    "```real_samples_labels = torch.ones(real_samples.size(0), 1).to(device=device)```\n",
    "```generated_samples_labels = torch.zeros(latent_space_samples.size(0), 1).to(device=device)```\n",
    "\n",
    "\n",
    "When retrying the MNIST download, it's advisable to utilize the updated URL from the ```MNIST.resources``` property to ensure adaptability to future changes.\n",
    "The training loop currently displays generated images every batch, which is redundant and resource-intensive. Consider reducing the frequency to, for example, every 10 batches.\n",
    "Refactoring the try/except block for downloading MNIST into a separate utility function would enhance the cleanliness of the training code.\n",
    "Incorporating high-level comments to elucidate the overall flow and architectural decisions would enhance code comprehensibility.\n",
    "Integrating validation or testing code to assess the GAN's performance would align with best practices in machine learning.\n",
    "Adding the iteration number to the loss prints would provide valuable context for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "NoneType = type(None)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import vgg11\n",
    "from torchvision.models import mobilenet_v2\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Add/adjust code.\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    try:\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    except:\n",
    "        print(\"Failed to download MNIST, retrying with different URL\")\n",
    "        # see: https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n",
    "        torchvision.datasets.MNIST.resources = [\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "             'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "             'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "             '9fb629c4189551a2d022fa330f9573f3'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "             'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "        ]\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # example data\n",
    "    real_samples, mnist_labels = next(iter(train_loader))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(16):\n",
    "        sub = fig.add_subplot(4, 4, 1 + i)\n",
    "        sub.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "        sub.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"Real images\")\n",
    "    display(fig)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Set up training\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    lr = 0.0001\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, mnist_labels) in enumerate(train_loader):\n",
    "\n",
    "            # Data for training the discriminator\n",
    "            real_samples = real_samples.to(device=device)\n",
    "            real_samples_labels = torch.ones(real_samples.size(0), 1).to(device=device)\n",
    "            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros(latent_space_samples.size(0), 1).to(device=device)\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            # Training the discriminator\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            # Data for training the generator\n",
    "            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n",
    "\n",
    "            # Training the generator\n",
    "            generator.zero_grad()\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "            # Show loss and samples generated\n",
    "            if n == batch_size - 1:\n",
    "                name = f\"Generate images\\n Epoch: {epoch} Loss D.: {loss_discriminator:.2f} Loss G.: {loss_generator:.2f}\"\n",
    "                generated_samples = generated_samples.detach().cpu().numpy()\n",
    "                fig = plt.figure()\n",
    "                for i in range(16):\n",
    "                    sub = fig.add_subplot(4, 4, 1 + i)\n",
    "                    sub.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                    sub.axis('off')\n",
    "                fig.suptitle(name)\n",
    "                fig.tight_layout()\n",
    "                clear_output(wait=False)\n",
    "                display(fig)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
